{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPflapr/wDGd8rCeomZtzdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zulfanHamka/technicaltestDE_web_berita/blob/main/backtrack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRFmUrjmbOw5",
        "outputId": "436da47a-f674-4cd7-9c18-b219dcfda8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silakan masukkan rentang tanggal untuk scraping.\n",
            "Masukkan tanggal mulai (YYYY-MM-DD): 2025-09-20\n",
            "Masukkan tanggal selesai (YYYY-MM-DD): 2025-09-21\n",
            "\n",
            "Memulai scraping untuk tanggal: 2025-09-20\n",
            "Total halaman ditemukan: 1\n",
            "Scraping halaman 1 dari 1...\n",
            "Berhasil: Saham Happy Hapsoro dan Garibaldi Thohir Masuk Radar IHSG Pekan Depan\n",
            "Berhasil: Saham Industri dan Teknologi Jadi Penggerak IHSG Sepekan, Sektor Finansial Tersendat\n",
            "Berhasil: Investor Asing Tarik Dana dari SBN, SRBI, Saham usai BI Rate Turun\n",
            "Berhasil: IHSG Berpotensi Tembus 8.246, Saham ASII, PGAS, hingga TLKM Jadi Favorit\n",
            "Berhasil: Investor Siap-Siap Terima Jatah IPO Merdeka Gold (EMAS), Analis Ramalkan Laba Tahun 2026\n",
            "Berhasil: Proyeksi Harga Emas Pekan Depan usai Kembali Tembus Rekor Tertinggi, Siap Cuan?\n",
            "Berhasil: IHSG Berpotensi Menguat Lagi, Simak Rekomendasi Saham BBCA & BBTN Cs Pekan Depan\n",
            "Berhasil: Ekspektasi dan Peluang Re-Rating Saham GOTO\n",
            "Berhasil: BRPT, DSSA, hingga TLKM Jadi Pendorong IHSG Tembus Rekor 8.051\n",
            "Berhasil: Sampoerna Agro (SGRO) Bakal Lepas 100% Kepemilikan di National Sago Prima\n",
            "Berhasil: Cukai Rokok SKT Disorot, Strategi GGRM Diversifikasi ke Produk Murah Dipertaruhkan\n",
            "Berhasil: IHSG Cetak Rekor ATH di 8.051, Kinerja Lampaui Indeks Malaysia & Singapura\n",
            "Berhasil: Saham Emiten Prajogo Pangestu (BRPT, CDIA) Paling Ramai Diburu Investor Kala IHSG Cetak Rekor 8.051\n",
            "Berhasil: Soechi Lines (SOCI) Bikin 2 Anak Usaha Baru di Marshall Islands\n",
            "Berhasil: Harga Emas Antam Naik Hari Ini, Ukuran 1 Gram Dibanderol Rp2,12 Juta\n",
            "Berhasil: Tabel Harga Emas Antam di Pegadaian Hari Ini, Sabtu 20 September 2025\n",
            "Berhasil: GOTO, BRMS, dan ARCI Dominasi Volume Transaksi Saat IHSG Rekor Tertinggi 8.051\n",
            "Berhasil: Harga Emas Perhiasan Hari Ini 20 September 2025, 24 Karat Mulai Rp1,7 Juta\n",
            "Berhasil: IHSG Sepekan All Time High di 8.051, Dana Asing Guyur Pasar Saham RI\n",
            "Berhasil: IHSG Pecah Rekor ATH Baru, Cek Saham Paling Cuan & Boncos Sepekan\n",
            "Berhasil: Saham Happy Hapsoro dan Garibaldi Thohir Masuk Radar IHSG Pekan Depan\n",
            "Berhasil: Saham Industri dan Teknologi Jadi Penggerak IHSG Sepekan, Sektor Finansial Tersendat\n",
            "Berhasil: Investor Asing Tarik Dana dari SBN, SRBI, Saham usai BI Rate Turun\n",
            "Berhasil: IHSG Berpotensi Tembus 8.246, Saham ASII, PGAS, hingga TLKM Jadi Favorit\n",
            "Berhasil: Investor Siap-Siap Terima Jatah IPO Merdeka Gold (EMAS), Analis Ramalkan Laba Tahun 2026\n",
            "Berhasil: Proyeksi Harga Emas Pekan Depan usai Kembali Tembus Rekor Tertinggi, Siap Cuan?\n",
            "Berhasil: IHSG Berpotensi Menguat Lagi, Simak Rekomendasi Saham BBCA & BBTN Cs Pekan Depan\n",
            "Berhasil: Ekspektasi dan Peluang Re-Rating Saham GOTO\n",
            "Berhasil: BRPT, DSSA, hingga TLKM Jadi Pendorong IHSG Tembus Rekor 8.051\n",
            "Berhasil: Sampoerna Agro (SGRO) Bakal Lepas 100% Kepemilikan di National Sago Prima\n",
            "Berhasil: Cukai Rokok SKT Disorot, Strategi GGRM Diversifikasi ke Produk Murah Dipertaruhkan\n",
            "Berhasil: IHSG Cetak Rekor ATH di 8.051, Kinerja Lampaui Indeks Malaysia & Singapura\n",
            "Berhasil: Saham Emiten Prajogo Pangestu (BRPT, CDIA) Paling Ramai Diburu Investor Kala IHSG Cetak Rekor 8.051\n",
            "Berhasil: Soechi Lines (SOCI) Bikin 2 Anak Usaha Baru di Marshall Islands\n",
            "Berhasil: Harga Emas Antam Naik Hari Ini, Ukuran 1 Gram Dibanderol Rp2,12 Juta\n",
            "Berhasil: Tabel Harga Emas Antam di Pegadaian Hari Ini, Sabtu 20 September 2025\n",
            "Berhasil: GOTO, BRMS, dan ARCI Dominasi Volume Transaksi Saat IHSG Rekor Tertinggi 8.051\n",
            "Berhasil: Harga Emas Perhiasan Hari Ini 20 September 2025, 24 Karat Mulai Rp1,7 Juta\n",
            "Berhasil: IHSG Sepekan All Time High di 8.051, Dana Asing Guyur Pasar Saham RI\n",
            "Berhasil: IHSG Pecah Rekor ATH Baru, Cek Saham Paling Cuan & Boncos Sepekan\n",
            "\n",
            "Memulai scraping untuk tanggal: 2025-09-21\n",
            "Total halaman ditemukan: 1\n",
            "Scraping halaman 1 dari 1...\n",
            "Berhasil: Proyeksi Analis soal Peluang Penurunan Cukai Rokok 2026\n",
            "Berhasil: Percepatan Rumah Subsidi, Bantalan Emiten Properti saat Daya Beli Lesu\n",
            "Berhasil: Anak Usaha ENRG Tingkatkan Produksi Blok Kampar dengan Sumur Kayuara-20\n",
            "Berhasil: Menakar Peluang Rebound Saham Bank BMRI, BBNI Cs di Era Suku Bunga Rendah\n",
            "Berhasil: CGS Sekuritas Puncaki Top Broker Sepekan, Transaksi Tembus Rp50,69 Triliun\n",
            "Berhasil: Harga Emas Antam Hari Ini, Minggu 21 September 2025 Termurah Rp1.111.000\n",
            "Berhasil: Menerka Arah IHSG Usai Tembus Rekor ATH Baru di Periode Black September\n",
            "Berhasil: Tabel Harga Buyback Emas Antam Hari Ini Minggu, 21 September 2025 & Besaran Pajaknya\n",
            "Berhasil: Harga Emas Perhiasan Hari Ini 21 September, Termurah Rp559 Ribu per Gram\n",
            "Berhasil: Dari IFII hingga MTWI, Ini Daftar Emiten yang Guyur Dividen Pekan Depan\n",
            "Berhasil: Pacu Ekspansi, Cahayasakti Investindo (CSIS) Rancang Rights Issue 1,04 Miliar Saham\n",
            "Berhasil: Harga Emas Antam & UBS serta Buyback di Pegadaian Hari Ini Minggu 21 September 2025\n",
            "Berhasil: 10 Top Laggards Sepekan saat IHSG Pecah Rekor ATH, Ada Saham AMMN, BMRI & BBCA\n",
            "Berhasil: Harga Emas Antam di Pegadaian Hari Ini Minggu, 21 September 2025 Melonjak Tajam\n",
            "Berhasil: Prediksi Nilai Tukar Rupiah terhadap Dolar AS Pekan Depan, Senin 22 September 2025\n",
            "Berhasil: Menanti Tuah India Geser China jadi Tujuan Utama Ekspor Minyak Sawit RI\n",
            "Berhasil: Adu Diskon Saham Farmasi Kalbe Farma (KLBF) dan Sido Muncul (SIDO)\n",
            "Berhasil: Mitra Keluarga (MIKA) dan Siloam (SILO), Emiten Rumah Sakit Diskon dalam 5 Tahun\n",
            "Berhasil: Proyeksi Analis soal Peluang Penurunan Cukai Rokok 2026\n",
            "Berhasil: Percepatan Rumah Subsidi, Bantalan Emiten Properti saat Daya Beli Lesu\n",
            "Berhasil: Anak Usaha ENRG Tingkatkan Produksi Blok Kampar dengan Sumur Kayuara-20\n",
            "Berhasil: Menakar Peluang Rebound Saham Bank BMRI, BBNI Cs di Era Suku Bunga Rendah\n",
            "Berhasil: CGS Sekuritas Puncaki Top Broker Sepekan, Transaksi Tembus Rp50,69 Triliun\n",
            "Berhasil: Harga Emas Antam Hari Ini, Minggu 21 September 2025 Termurah Rp1.111.000\n",
            "Berhasil: Menerka Arah IHSG Usai Tembus Rekor ATH Baru di Periode Black September\n",
            "Berhasil: Tabel Harga Buyback Emas Antam Hari Ini Minggu, 21 September 2025 & Besaran Pajaknya\n",
            "Berhasil: Harga Emas Perhiasan Hari Ini 21 September, Termurah Rp559 Ribu per Gram\n",
            "Berhasil: Dari IFII hingga MTWI, Ini Daftar Emiten yang Guyur Dividen Pekan Depan\n",
            "Berhasil: Pacu Ekspansi, Cahayasakti Investindo (CSIS) Rancang Rights Issue 1,04 Miliar Saham\n",
            "Berhasil: Harga Emas Antam & UBS serta Buyback di Pegadaian Hari Ini Minggu 21 September 2025\n",
            "Berhasil: 10 Top Laggards Sepekan saat IHSG Pecah Rekor ATH, Ada Saham AMMN, BMRI & BBCA\n",
            "Berhasil: Harga Emas Antam di Pegadaian Hari Ini Minggu, 21 September 2025 Melonjak Tajam\n",
            "Berhasil: Prediksi Nilai Tukar Rupiah terhadap Dolar AS Pekan Depan, Senin 22 September 2025\n",
            "Berhasil: Menanti Tuah India Geser China jadi Tujuan Utama Ekspor Minyak Sawit RI\n",
            "Berhasil: Adu Diskon Saham Farmasi Kalbe Farma (KLBF) dan Sido Muncul (SIDO)\n",
            "Berhasil: Mitra Keluarga (MIKA) dan Siloam (SILO), Emiten Rumah Sakit Diskon dalam 5 Tahun\n",
            "\n",
            "Scraping selesai! Data tersimpan di file: data_berita_bisnis_2025-09-20_to_2025-09-21.json\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import sys\n",
        "\n",
        "# Headers untuk request\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n",
        "}\n",
        "\n",
        "# Fungsi ambil isi artikel\n",
        "def get_article_content(link):\n",
        "    try:\n",
        "        res = requests.get(link, headers=headers)\n",
        "        soup = BeautifulSoup(res.text, 'lxml')\n",
        "        div_content = soup.find('article', class_='detailsContent')\n",
        "        if not div_content:\n",
        "            return \"Konten tidak ditemukan\"\n",
        "        paragraphs = div_content.find_all('p')\n",
        "        content = ' '.join([p.get_text(strip=True) for p in paragraphs])\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat mengambil artikel: {link} | {e}\")\n",
        "        return ''\n",
        "\n",
        "# Fungsi validasi input tanggal\n",
        "def get_validated_date(prompt):\n",
        "    while True:\n",
        "        date_str = input(prompt)\n",
        "        try:\n",
        "            valid_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "            return valid_date, date_str\n",
        "        except ValueError:\n",
        "            print(\"Format tanggal salah. Silakan gunakan format YYYY-MM-DD.\")\n",
        "\n",
        "# Ambil input tanggal dari pengguna\n",
        "print(\"Silakan masukkan rentang tanggal untuk scraping.\")\n",
        "start_date, start_date_str = get_validated_date(\"Masukkan tanggal mulai (YYYY-MM-DD): \")\n",
        "end_date, end_date_str = get_validated_date(\"Masukkan tanggal selesai (YYYY-MM-DD): \")\n",
        "\n",
        "# Validasi urutan tanggal\n",
        "if start_date > end_date:\n",
        "    print(\"\\nError: Tanggal mulai tidak boleh lebih akhir dari tanggal selesai.\")\n",
        "    sys.exit()\n",
        "\n",
        "current_date = start_date\n",
        "\n",
        "# List untuk menampung hasil scrape\n",
        "all_articles_data = []\n",
        "\n",
        "# Loop utama untuk setiap tanggal\n",
        "while current_date <= end_date:\n",
        "    date_to_scrape = current_date.strftime('%Y-%m-%d')\n",
        "    print(f\"\\nMemulai scraping untuk tanggal: {date_to_scrape}\")\n",
        "\n",
        "    try:\n",
        "        # Cari total halaman untuk tanggal ini\n",
        "        url_first = f'https://www.bisnis.com/index?categoryId=194&date={date_to_scrape}&type=indeks&page=1#'\n",
        "        res_first = requests.get(url_first, headers=headers)\n",
        "        soup_first = BeautifulSoup(res_first.text, 'lxml')\n",
        "\n",
        "        last_page = 1\n",
        "        paging_element = soup_first.find('p', class_='pagingLabel')\n",
        "        if paging_element:\n",
        "            try:\n",
        "                last_page = int(paging_element.get_text(strip=True).split()[1])\n",
        "            except (IndexError, ValueError):\n",
        "                print(f\"Tidak dapat memparsing jumlah halaman untuk tanggal {date_to_scrape}.\")\n",
        "        print(f\"Total halaman ditemukan: {last_page}\")\n",
        "\n",
        "        # Loop untuk setiap halaman\n",
        "        for page in range(1, last_page + 1):\n",
        "            print(f\"Scraping halaman {page} dari {last_page}...\")\n",
        "            url = f'https://www.bisnis.com/index?categoryId=194&date={date_to_scrape}&type=indeks&page={page}#'\n",
        "\n",
        "            res = requests.get(url, headers=headers)\n",
        "            soup = BeautifulSoup(res.text, 'lxml')\n",
        "            articles = soup.find_all('div', class_='artItem')\n",
        "\n",
        "            if not articles:\n",
        "                print(f\"Tidak ada artikel ditemukan di halaman {page}.\")\n",
        "                continue\n",
        "\n",
        "            # Loop untuk setiap artikel di halaman\n",
        "            for art in articles:\n",
        "                try:\n",
        "                    a_tag = art.find('a')\n",
        "                    h4_tag = art.find('h4')\n",
        "\n",
        "                    if not a_tag or not h4_tag:\n",
        "                        continue\n",
        "\n",
        "                    title = h4_tag.get_text(strip=True)\n",
        "                    link = a_tag['href']\n",
        "\n",
        "                    # Ambil & format tanggal dari URL\n",
        "                    try:\n",
        "                        url_parts = link.split('/')\n",
        "                        date_from_url_str = url_parts[4]\n",
        "                        year = date_from_url_str[0:4]\n",
        "                        month = date_from_url_str[4:6]\n",
        "                        day = date_from_url_str[6:8]\n",
        "                        time_info = f\"{year}-{month}-{day}\"\n",
        "                    except (IndexError, TypeError):\n",
        "                        time_info = \"Tanggal tidak ditemukan di URL\"\n",
        "\n",
        "                    content = get_article_content(link)\n",
        "\n",
        "                    # Simpan data ke dictionary\n",
        "                    article_dict = {\n",
        "                        'Title': title,\n",
        "                        'Link': link,\n",
        "                        'Time': time_info,\n",
        "                        'Content': content\n",
        "                    }\n",
        "                    all_articles_data.append(article_dict)\n",
        "\n",
        "                    print(f\"Berhasil: {title}\")\n",
        "                    time.sleep(1) # Jeda antar artikel\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing artikel: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Jeda antar halaman\n",
        "            time.sleep(2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal memproses tanggal {date_to_scrape}: {e}\")\n",
        "\n",
        "    # Lanjut ke tanggal berikutnya\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "\n",
        "# Simpan hasil ke file JSON\n",
        "if all_articles_data:\n",
        "    file_name = f'data_berita_bisnis_{start_date_str}_to_{end_date_str}.json'\n",
        "    with open(file_name, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_articles_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"\\nScraping selesai! Data tersimpan di file: {file_name}\")\n",
        "else:\n",
        "    print(\"\\nScraping selesai, namun tidak ada data yang berhasil dikumpulkan.\")"
      ]
    }
  ]
}